{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/scalabrinig/cdProjetoAplicadoIV/blob/master/projeto/cd_projeto_aplicado_IV_entrega_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<img src=\"https://raw.githubusercontent.com/joaonetto/projetoAplicado-IV/refs/heads/main/Imagem/Mackenzie.png\" width=\"25%\" align=\"left\"/>\n",
    "\n"
   ],
   "metadata": {
    "id": "Ux5TSX--qOft"
   }
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# **PROJETO APLICADO IV - Ciência de Dados EaD - 2026/01**\n",
    "\n",
    "\n",
    "# **Entrega 1**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Titulo do Projeto**:\n",
    "\n",
    "### *ChronoSec*: Detecção Comportamental e Séries Temporais para Segurança de Login (UEBA) em Eventos Google\n",
    "---"
   ],
   "metadata": {
    "id": "-UJ6Rj9jrJFM"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#@title **Identificação do Grupo e Opção do Projeto**\n",
    "\n",
    "#@markdown Integrantes do Grupo, nome completo em ordem alfabética (*informe: \\<nome\\>, \\<matrícula\\>*)\n",
    "Aluno1 = 'João Silveira Campos Netto, 10441670' #@param {type:\"string\"}\n",
    "Aluno2 = 'Alex Luiz Rabelo, 10442968' #@param {type:\"string\"}\n",
    "Aluno3 = 'Antônio Henrique Caldas Mello, 10442968' #@param {type:\"string\"}"
   ],
   "metadata": {
    "id": "yky3TEyXoGaY",
    "ExecuteTime": {
     "end_time": "2026-02-18T21:45:22.165371Z",
     "start_time": "2026-02-18T21:45:22.143118Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Introdução**\n",
    "\n",
    "Processos de autenticação geram sinais ricos para segurança: falhas repetidas, desafios de MFA, mudanças de localização e padrões de horário. Em cenários de credenciais comprometidas, ataques automatizados e abuso de sessão, esses sinais costumam aparecer como anomalias temporais e comportamentais, muitas vezes antes de um incidente maior.\n",
    "\n",
    "Este projeto propõe um produto analítico, implementado em Jupyter Notebooks, para explorar dados de login (pseudonimizado) provenientes da plataforma Google e aplicar técnicas de Séries Temporais e UEBA (User and Entity Behavior Analytics) para identificar desvios relevantes, como “Impossible Travel”, picos de frequência, sequências incomuns de eventos e mudanças no padrão de horário. A proposta combina regras explicáveis e modelos de aprendizado de máquina, com foco em reprodutibilidade e comunicação clara para um cliente (SOC/IAM).\n",
    "\n",
    "UEBA é uma abordagem consolidada para detectar comportamentos anormais de usuários e entidades usando análises comportamentais e ML.\n",
    "\n"
   ],
   "metadata": {
    "id": "3_YOokpLogtZ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Motivações e justificativa**\n",
    "\n",
    "### Motivação\n",
    "1.\t**Identidade virou o novo perímetro**\n",
    "\n",
    "Grande parte dos incidentes modernos começa por abuso de credenciais (phishing, reutilização de senhas, token/session hijacking). O “momento do login” é um dos pontos mais ricos para detectar sinais iniciais de comprometimento, antes do dano maior.\n",
    "\n",
    "2. **Logs de autenticação são séries temporais naturalmente**\n",
    "\n",
    "Eventos de login têm ordem, frequência, dependência temporal e contexto (MFA, falha/sucesso, desafio), o que torna o problema ideal para técnicas de séries temporais e modelagem sequencial. Em vez de olhar eventos isolados, o projeto olha trajetórias de comportamento.\n",
    "\n",
    "3. **Necessidade de reduzir ruído e acelerar triagem no SOC**\n",
    "\n",
    "Times de segurança recebem muitos alertas, mas poucos são realmente relevantes. Um produto analítico que gere score + explicação ajuda a priorizar casos e reduzir tempo de investigação (MTTA/MTTR), com impacto direto na operação.\n",
    "\n",
    "4. **“Impossible Travel” e padrões de sequência são sinais de alto valor**\n",
    "\n",
    "Mudanças geográficas incompatíveis com o tempo, bursts de falhas e cadeias raras de autenticação são padrões amplamente utilizados na indústria, por serem interpretáveis e úteis na prática (mesmo antes do deep learning).\n",
    "\n",
    "### Justificativa\n",
    "1.\t**Justificativa técnica: melhor modelar comportamento do que eventos pontuais**\n",
    "\n",
    "Ataques de conta comprometida muitas vezes não são detectados por uma única característica. Eles aparecem como mudança de padrão: novo país/cidade, horário incomum, sequência anômala (falha→desafio→sucesso), ou velocidade impossível.\n",
    "\n",
    "2. **Séries temporais (janelas, entropia, transições Markov, LSTM) são adequadas porque capturam:**\n",
    "  - dependência temporal (antes/depois),\n",
    "  - regularidade vs desvio (baseline do usuário),\n",
    "  - anomalias contextuais (o que é normal para um usuário pode ser estranho para outro).\n",
    "\n",
    "3. **Justificativa de negócio: prevenção e redução de impacto**\n",
    "\n",
    "Detectar rapidamente abuso de credenciais reduz:\n",
    "- fraudes e acessos indevidos,\n",
    "- indisponibilidade por resposta a incidentes,\n",
    "- custos de investigação e retrabalho,\n",
    "- exposição reputacional e risco regulatório.\n",
    "\n",
    "Além disso, gera um ativo “produto”: um motor de risco reaproveitável em outras aplicações (VPN, IAM, SSO, apps internos).\n",
    "\n",
    "4. **Justificativa metodológica: abordagem em camadas (explicável + ML + deep learning)**\n",
    "\n",
    "O projeto é justificável academicamente e operacionalmente porque entrega valor incremental:\n",
    "- Regras explicáveis (rápidas de implementar e fáceis de defender em auditoria),\n",
    "- Modelos clássicos (melhor generalização e redução de falsos positivos),\n",
    "- Modelos sequenciais (Markov/LSTM) (capturam comportamento mais sutil).\n",
    "\n",
    "Isso cria um caminho claro de maturidade do produto.\n",
    "\n",
    "4. **Justificativa de dados: dataset apropriado e enriquecido**\n",
    "\n",
    "Os dados anonimizados + geolocalização permitem medir:\n",
    "- deslocamento (lat/lon + tempo),\n",
    "- incerteza (accuracy_radius_km),\n",
    "- contexto de autenticação (MFA/desafios/falhas),\n",
    "- sinal auxiliar (É suspeito) para validação.\n",
    "\n",
    "- Ou seja: há base suficiente para construir features robustas e validar hipóteses.\n",
    "\n",
    "5. **Justificativa extensionista (ODS 9 e 12)**\n",
    "- ODS 9: fortalecer resiliência e segurança de infraestrutura digital baseada em identidade.\n",
    "- ODS 12: reduzir desperdício operacional (menos alertas inúteis, menos horas gastas, menos custos de resposta).\n",
    "\n",
    "A entrega pública (código + dataset pseudonimizado + documentação) amplia o benefício para a comunidade acadêmica e profissionais de segurança."
   ],
   "metadata": {
    "id": "jE9yYM31oqr3"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Objetivo**\n",
    "\n",
    "Este trabalho tem como objetivo desenvolver um produto analítico baseado em séries temporais para detectar e explicar comportamentos anômalos em processos de login (eventos de autenticação) a partir de dados anonimizados da plataforma Google enriquecidos com geolocalização. A pretensão central é transformar registros brutos de autenticação em informação acionável para Cyber Security, permitindo identificar rapidamente padrões compatíveis com abuso de credenciais, automação maliciosa e tentativas de acesso indevido, com foco em priorização operacional e redução de ruído na investigação.\n",
    "\n",
    "Como metas, o projeto busca:\n",
    "1. modelar o comportamento típico de usuários e domínios ao longo do tempo (baseline) e medir desvios relevantes;\n",
    "2. implementar mecanismos de detecção para cinco dimensões complementares do problema: frequência/velocidade de tentativas (Velocity Checks), viagens impossíveis (Impossible Travel), sequências incomuns de eventos de autenticação via cadeias de Markov, mudanças no padrão de horário por entropia temporal, e aprendizado de comportamento por modelos LSTM;\n",
    "3. consolidar essas evidências em um score de risco por evento acompanhado de justificativas interpretáveis, para apoiar triagem e tomada de decisão;\n",
    "4. entregar um experimento executável e reproduzível em Jupyter Notebooks, incluindo pipeline de preparação de dados, extração de features, treinamento/avaliação de modelos e geração de relatórios com estudos de caso.\n",
    "\n",
    "Ao final, espera-se disponibilizar uma solução que demonstre, de forma mensurável, a capacidade de identificar anomalias comportamentais e explicar por que um evento foi considerado suspeito, além de apresentar uma proposta extensionista alinhada às ODS 9 e 12 por meio da publicação do método e de materiais reprodutíveis (incluindo um dataset compatível com o esquema de dados), contribuindo para a comunidade interessada em segurança de identidade e análise temporal.\n",
    "\n"
   ],
   "metadata": {
    "id": "Tax--lV7ov7G"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Descrição da base de dados**\n",
    "\n",
    "Os dados utilizados neste projeto são provenientes de **streaming**, ou seja, consistem em logs gerados por evento. Dessa forma, a cada nova ação relevante (por exemplo, uma tentativa de autenticação), um novo registro é criado e pode ser coletado para análise e tomada de decisão em tempo quase real.mada de decisão, abaixo segue seu formato e sua descrição:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"Data\": \"2024-12-31T21:10:26-0300\",\n",
    "  \"Usuário\": \"USR701910@acme-d67a0e6c.org.br\",\n",
    "  \"Evento\": \"login_success\",\n",
    "  \"Descrição\": \"USR701910@acme-d67a0e6c.org.br logged in\",\n",
    "  \"Tipo de login\": \"google_password\",\n",
    "  \"Tipo de desafio\": \"password\",\n",
    "  \"Tipo de falha de login\": \"Desconhecido\",\n",
    "  \"É suspeito\": false,\n",
    "  \"É o segundo fator\": false,\n",
    "  \"Nome da ação confidencial\": null,\n",
    "  \"Domínio\": \"acme-d67a0e6c.org.br\",\n",
    "  \"cidade\": \"São Paulo\",\n",
    "  \"estado\": \"São Paulo\",\n",
    "  \"país\": \"Brazil\",\n",
    "  \"país ISO\": \"BR\",\n",
    "  \"accuracy_radius_km\": 20,\n",
    "  \"latitude\": -23.5475,\n",
    "  \"longitude\": -46.6361,\n",
    "  \"__geo_source\": \"mmdb\",\n",
    "  \"__geo_error\": null\n",
    "}\n",
    "```\n",
    "\n",
    "### *Descrição dos campos*:\n",
    "\n",
    "1) *Data*\n",
    "- **O que é**: timestamp do evento, em ISO 8601 com timezone (ex.: -0300).\n",
    "- **Para que serve**: no projeto: é a coluna central para séries temporais: janelas (5min, 1h, 24h), ordenação de sequência, cálculo de delta_t entre eventos e agregações por hora/dia/semana.\n",
    "\n",
    "2) *Usuário*\n",
    "- **O que é**: identificador do usuário anonimizado.\n",
    "- **Para que serve**: chave para construir o baseline comportamental e sequências por usuário. Permite comparar *“o normal”* vs *“o desvio”* do próprio usuário.\n",
    "\n",
    "3) *Evento*\n",
    "- **O que é**: tipo do evento (ex.: login_success, login_failure, login_challenge, login_verification, logout, etc.).\n",
    "- **Para que serve**: base para:\n",
    "\t- contagem e frequência,\n",
    "\t- cadeias de Markov e sequências,\n",
    "\t- modelagem LSTM,\n",
    "\t- caracterização de sessões (ex.: login→logout).\n",
    "\n",
    "4) *Descrição*\n",
    "- **O que é**: texto descritivo do evento (geralmente legível/humano).\n",
    "- **Para que serve**: suporte para interpretação e auditoria (explicabilidade). Pode ser usado para validações, amostragens e exemplos no relatório.\n",
    "\n",
    "5) *Tipo de login*\n",
    "- **O que é**: mecanismo/canal de autenticação (ex.: google_password, reauth, exchange, Desconhecido).\n",
    "- **Para que serve**: feature de contexto para risco; certos tipos podem ter perfis diferentes de ameaça e normalidade. Auxilia alerta.\n",
    "\n",
    "6) *Tipo de desafio*\n",
    "- **O que é**: tipo de desafio apresentado no fluxo (ex.: password, device_prompt, google_authenticator, security_key, none, etc.).\n",
    "- **Para que serve**: sinaliza a “trilha” do login e suporte à análise sequencial e aprendizado. Também ajuda a medir fricção/segurança (ex.: desafios fortes vs fracos).\n",
    "\n",
    "7) *Tipo de falha de login*\n",
    "- **O que é**: categoria/motivo de falha de login.\n",
    "- **Para que serve**: quando preenchido, seria essencial para classificar ataques (senha incorreta, conta bloqueada, etc.). Nesta base, aparece como “Desconhecido”, então o uso tende a ser limitado (mas o campo deve permanecer no schema para futura coleta/análise).\n",
    "\n",
    "8) *É suspeito*\n",
    "- **O que é**: flag (true/false) indicando se o evento já foi marcado como suspeito por alguma origem/regra prévia.\n",
    "- **Para que serve**: útil como proxy de rótulo para validação inicial (ex.: avaliar precision/recall) e para análises de casos. Também pode ser usado como feature (com cautela, para não “vazar” decisão).\n",
    "\n",
    "9) *É o segundo fator*\n",
    "- **O que é**: flag (true/false) indicando ocorrência/uso de segundo fator.\n",
    "- **Para que serve**: indicador de MFA; essencial para explicar e priorizar risco (ex.: “viagem impossível sem segundo fator”).\n",
    "\n",
    "10) *Nome da ação confidencial*\n",
    "- **O que é**: nome de uma ação sensível (quando aplicável) relacionada a risco/segurança.\n",
    "- **Para que serve**: correlacionar eventos de autenticação com ações sensíveis (ex.: bloqueios, alterações de recovery, etc.), enriquecendo o score e estudos de caso.\n",
    "\n",
    "11) *Domínio*\n",
    "- **O que é**: domínio/tenant associado ao usuário e ao evento (também pseudonimizado).\n",
    "- **Para que serve**: agregações por organização, deteção de surtos por domínio, e perfis distintos (um domínio pode ter comportamento diferente de outro).\n",
    "\n",
    "---\n",
    "\n",
    "### *Campos de geolocalização (enriquecimento)*\n",
    "\n",
    "12) *cidade*\n",
    "- **O que é**: cidade inferida via geolocalização de IP.\n",
    "- **Para que serve**: contexto para “Impossible Travel”, clusters por cidade, baseline de locais frequentes e investigações.\n",
    "\n",
    "13) *estado*\n",
    "- **O que é**: estado/região administrativa.\n",
    "- **Para que serve**: agregação intermediária (útil quando cidade é instável) e análises por região.\n",
    "\n",
    "14) *país*\n",
    "- **O que é**: país inferido.\n",
    "- **Para que serve**: forte sinal para “Impossible Travel” e anomalias por deslocamento internacional.\n",
    "\n",
    "15) *país ISO*\n",
    "- **O que é**: código ISO do país (ex.: BR, US).\n",
    "- **Para que serve**: padronização para relatórios, mapas e integração com outros sistemas.\n",
    "\n",
    "16) *accuracy_radius_km*\n",
    "- **O que é**: raio estimado de acurácia (km) da geolocalização (incerteza).\n",
    "- **Para que serve**: redução de falsos positivos em velocidade/viagem impossível: deslocamentos pequenos podem ser ruído quando a acurácia é baixa; deslocamentos devem ser “descontados” pelo erro.\n",
    "\n",
    "17) *latitude*\n",
    "- **O que é**: latitude estimada.\n",
    "- **Para que serve**: cálculo de distância (Haversine) e métricas de deslocamento, além de features para LSTM.\n",
    "\n",
    "18) *longitude*\n",
    "- **O que é**: longitude estimada.\n",
    "- **Para que serve**: junto com latitude, cálculo de distância e construção de trajetórias.\n",
    "\n",
    "19) *__geo_source*\n",
    "- **O que é**: fonte do enriquecimento geo (ex.: mmdb, ipgeolocation, cache).\n",
    "- **Para que serve**: qualidade e rastreabilidade do enrichment; fontes diferentes podem ter precisão distinta. Útil para filtros e explicações (“geo veio de cache/mmdb”).\n",
    "\n",
    "20) *__geo_error*\n",
    "- **O que é**: erro ocorrido durante o enriquecimento geo (quando existir).\n",
    "- **Para que serve**: flag de qualidade; eventos com erro devem ser tratados como “geo inválido” (não usar em impossible travel/velocidade)."
   ],
   "metadata": {
    "id": "VG897rGOo1Rv"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# **Referências (bibliográficas e técnicas)**\n",
    "\n",
    "A seleção abaixo sustenta os principais pilares (UEBA, Impossible Travel, sequências com Markov e anomalia com LSTM):\n",
    "1. UEBA (conceito e uso em detecção comportamental)\n",
    "- IBM — [visão geral e definição de UEBA](https://www.ibm.com/think/topics/ueba).\n",
    "- Rapid7 — [fundamentos de UEBA e relação com credenciais comprometidas e comportamento anômalo](https://www.rapid7.com/fundamentals/user-behavior-analytics).\n",
    "2. Impossible Travel (prática de mercado / detecção)\n",
    "- vCalc - [Haversine - Distance](https://www.vcalc.com/wiki/vcalc/haversine-distance)\n",
    "- Google - [Detecting Impossible Travel, with Google SecOps: Part 1](https://security.googlecloudcommunity.com/community-blog-42/detecting-impossible-travel-with-google-secops-part-1-3892)\n",
    "- Microsoft Defender for Cloud Apps — [política de anomalia e “impossible travel” com mitigação de falsos positivos](https://learn.microsoft.com/en-us/defender-cloud-apps/anomaly-detection-policy#impossible-travel).\n",
    "- Microsoft Tech Community — [explicação do racional do “Impossible Travel”](https://techcommunity.microsoft.com/blog/microsoftthreatprotectionblog/detecting-and-remediating-impossible-travel/3366017).\n",
    "3.\tModelagem sequencial com Markov para anomalia\n",
    "- Ren (2017) — [Anomaly detection based on a dynamic Markov model](https://www.sciencedirect.com/science/article/pii/S0020025517307302).\n",
    "- Haque (ACM, 2017) — [Markov Chain Modeling for Anomaly Detection in High Performance Computing System Logs](https://dl.acm.org/doi/epdf/10.1145/3152493.3152559).\n",
    "4. LSTM/Autoencoders para detecção de anomalia em séries temporais\n",
    "- Maleki (2021) — [Unsupervised anomaly detection with LSTM autoencoders using statistical data-filtering](https://www.sciencedirect.com/science/article/abs/pii/S1568494621003665).\n"
   ],
   "metadata": {
    "id": "KucOdKJLo3bG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#@title **Avaliação**\n",
    "Introducao = 10 #@param {type:\"slider\", min:0, max:10, step:1}\n",
    "\n",
    "Fonte_dos_dados = 10 #@param {type:\"slider\", min:0, max:10, step:1}\n",
    "\n",
    "Solucao_proposta = 10 #@param {type:\"slider\", min:0, max:10, step:1}\n",
    "\n",
    "Referencias = 10 #@param {type:\"slider\", min:0, max:10, step:1}"
   ],
   "metadata": {
    "id": "Ad98o5dRo8Wq",
    "ExecuteTime": {
     "end_time": "2026-02-18T21:45:22.252518Z",
     "start_time": "2026-02-18T21:45:22.172198Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "#@title **Nota Final**\n",
    "nota = 0.30*Introducao + 0.30*Fonte_dos_dados + 0.30*Solucao_proposta + 0.10*Referencias\n",
    "\n",
    "print(f'Nota da entrega {nota :.1f}')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "alunos = pd.DataFrame()\n",
    "\n",
    "lista_nome = []\n",
    "\n",
    "for i in range(1,3):\n",
    "  exec(\"if Aluno\" + str(i) + \" !='None':  lista = Aluno\" + str(i) + \".split(','); lista_nome.append(lista[0]);\")\n",
    "\n",
    "alunos['nome'] = lista_nome\n",
    "alunos['nota'] = np.round(nota,1)\n",
    "print()\n",
    "display(alunos)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "id": "8R_VW8bEpKvN",
    "outputId": "0b59fd57-1881-46d9-8671-d6355e5ee933",
    "ExecuteTime": {
     "end_time": "2026-02-18T21:46:09.329867Z",
     "start_time": "2026-02-18T21:46:09.296542Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nota da entrega 10.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                         nome  nota\n",
       "0  João Silveira Campos Netto  10.0\n",
       "1            Alex Luiz Rabelo  10.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nome</th>\n",
       "      <th>nota</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>João Silveira Campos Netto</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alex Luiz Rabelo</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 5
  }
 ]
}
